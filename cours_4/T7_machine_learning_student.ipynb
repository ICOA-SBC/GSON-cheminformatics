{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talktorial 7\n",
    "\n",
    "# Ligand-based screening: machine learning\n",
    "\n",
    "#### Developed in the CADD seminars 2017 and 2018, AG Volkamer, Charité/FU Berlin \n",
    "\n",
    "Jan Philipp Albrecht and Jacob Gora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim of this talktorial\n",
    "\n",
    "Due to larger available data sources, machine learning (ML) gained momentum in drug discovery and especially in ligand-based virtual screening. In this talktorial, we will learn how to use different supervised ML algorithms to predict the activity of novel compounds against our target of interest (EGFR).\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "* Different fingerprints to encode the molecules for usage in ML\n",
    "* Different ML algorithms and their application\n",
    "* Evaluation of ML model performance\n",
    "\n",
    "### Theory\n",
    "\n",
    "* Introduce different types of fingerprints\n",
    "* Different types of supervised ML algorithms\n",
    "* Model performance evaluation and measurements \n",
    "\n",
    "### Practical\n",
    "\n",
    "* Set up and evaluation of a ML-based screening pipeline for potential EGFR inhibitors\n",
    "\n",
    "## References\n",
    "\n",
    "* RdKit fingerprints, e.g. see [presentation by G. Landrum at rdkit UGM 2012](https://www.rdkit.org/UGM/2012/Landrum_RDKit_UGM.Fingerprints.Final.pptx.pdf):\n",
    "* ML:\n",
    "    * Random forest (RF): [http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf](http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf)\n",
    "    * Support vector machines (SVM): [https://link.springer.com/article/10.1007%2FBF00994018](https://link.springer.com/article/10.1007%2FBF00994018)\n",
    "    * Artificial neural networks (ANN): [https://www.frontiersin.org/research-topics/4817/artificial-neural-networks-as-models-of-neural-information-processing](https://www.frontiersin.org/research-topics/4817/artificial-neural-networks-as-models-of-neural-information-processing)\n",
    "* Performance: \n",
    "    * [Sensitivity_and_specificity (wikipedia)](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)\n",
    "    * [Roc curve and AUC (wikipedia)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve)\n",
    "* See also [git hub notebook by B. Merget](https://github.com/Team-SKI/Publications/tree/master/Profiling_prediction_of_kinase_inhibitors) from [*J. Med. Chem.*, 2017, 60, 474−485](https://pubs.acs.org/doi/10.1021/acs.jmedchem.6b01611) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "## Theory\n",
    "\n",
    "<img src=\"./images/ML_overview.png\" width=\"200\" align='right'>\n",
    "\n",
    "To successfully apply ML, we need a large data set of molecules, a molecular encoding, a label per molecule in the data set, and a ML algorithm to train a model. Then, we can make predictions for new molecules.\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "For ML, molecules need to be converted into a list of features. Often molecular fingerprints are used as representation. \n",
    "\n",
    "Fingerprints used in this talktorial and implemented in rdkit (more info can be found in a  [presentation by G. Landrum](https://www.rdkit.org/UGM/2012/Landrum_RDKit_UGM.Fingerprints.Final.pptx.pdf)):\n",
    "* **maccs**: MACCS keys are 166 bit structural key descriptors in which each bit is associated with a SMARTS pattern.\n",
    "* **ecfp4** and *ecfp6*: Extended-Connectivity Fingerprints (ECFPs) are circular topological fingerprints designed for molecular characterization, similarity searching, and structure-activity modeling. Most important parameters of ECFPs are maximum diameter and fingerprint length. The so called diameter specifies the maximum diameter of the circular neighborhoods considered for each atom. Here there are two diameters: 4 and 6. The length parameter specifies the length of the bit string representation. The default length is 2048.\n",
    "* **torsion**: The Torsion Fingerprint Deviation (TFD) extracts, weights, and compares Torsion Fingerprints from a query molecule and generated conformations under consideration of acyclic bonds as well as ring systems.\n",
    "* **rdk5**: rdk5 is a path based fingerprint. A path fingerprint is generated by exhaustively enumerating all linear fragments of a molecular graph up to a given size and then hashing these fragments into a fixed-length bit vector.\n",
    "\n",
    "### Machine Learning (ML)\n",
    "\n",
    "ML can be applied for (see also [scikit-learn page](http://scikit-learn.org/stable/)):\n",
    "\n",
    "* **Classification (supervised)**: Identify to which category an object belongs (Nearest neighbors, Naive Bayes, RF, SVM, ...)\n",
    "* Regression: Prediction of a continuous-values attribute associated with an object\n",
    "* Clustering (unsupervised): Automated grouping of similar objects into sets (see **talktorial 5**)\n",
    "\n",
    "#### Supervised learning\n",
    "\n",
    "Learning algorithm creates rules by finding patterns in the training data. \n",
    "<img src=\"./images/RF_example.png\" width=\"250\" align='right'>\n",
    "* **Random Forest (RF)**: Multiple decision trees which produce a mean prediction.\n",
    "\n",
    "* **Support Vector Machines (SVM)**: SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces. Classifier based on the idea of maximizing the margin as objective function.  \n",
    "\n",
    "    <img src=\"./images/ANN_wiki.png\" width=\"150\" align='right'>\n",
    "* **Artificial neural networks (ANNs)**: An ANN is based on a collection of connected units or nodes called artificial neurons which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. (Figure from Wikipedia)\n",
    " \n",
    "#### Validation strategy: K-fold cross validation\n",
    "\n",
    "* This model validation technique splits the dataset in two groups in an iterative manner:\n",
    "    * Training data set: Considered as the known dataset on which the model is trained\n",
    "    * Test dataset: Unknown dataset on which the model is then tested\n",
    "    * Process is repeated k-times\n",
    "    \n",
    "* The goal is to test the ability of the model to predict data which it has never seen before in order to flag problems known as over-fitting and to assess the generalization ability of the model.\n",
    "\n",
    "#### Performance measures\n",
    "<img src=\"./images/FP_TP_fig.png\" width=\"250\" align='right'>\n",
    "\n",
    "* **Sensitivity**, also true positive rate: TPR = TP/(FN+TP)\n",
    "* **Specificity**, also true negative rate: TNR = TN/(FP + TN)\n",
    "* **Accuracy**, also the trueness: ACC = (TP + TN)/(TP + TN + FP + FN)\n",
    "* **ROC-curve**, receiver operating characteristic curve\n",
    "    * A graphical plot that illustrates the diagnostic ability of our classifier\n",
    "    * Plots the sensitivity against the specificity\n",
    "* **AUC**, the area under the roc curve (AUC):  \n",
    "    * Describes the probability that a classifier will rank a randomly chosen positive instance higher than a negative one\n",
    "    * Values between 0 and 1, the higher the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, f'../corrections/exercices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "# General:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# rdkit:\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import RDKFingerprint\n",
    "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n",
    "from rdkit.Chem.AllChem import GetHashedTopologicalTorsionFingerprintAsBitVect\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.DataStructs import ConvertToNumpyArray\n",
    "\n",
    "# sklearn:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "# from sklearn.manifold import MDS\n",
    "\n",
    "# matplotlib:\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# seaborn:\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "We will work on EGFR (Epidermal growth factor receptor) kinase data for now.\n",
    "\n",
    "But before starting, we will define two functions to help us creating the data frame we will work with.\n",
    "The first method is named `calculate_fp` and calculates the molecular fingerprint of a molecule. The user has the choice between:\n",
    "* maccs\n",
    "* ecfp4 and ecfp6\n",
    "* torsion\n",
    "* rdk5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML import exo_calculate_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_calculate_fp.example(3) # rdkit molecule don't show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fp(mol, method='maccs', n_bits=2048):\n",
    "    ## mol = Chem molecule object\n",
    "    ## method can be : 'maccs', 'ecfp4', 'ecfp6', 'torsion' or 'rdk5'\n",
    "    ## depending on the method chosen, use the following functions :\n",
    "    ##                     MACCSkeys.GenMACCSKeys(mol), \n",
    "    ##                     GetMorganFingerprintAsBitVect(mol, radius=, nBits=n_bits, useFeatures=False),\n",
    "    ##                     GetHashedTopologicalTorsionFingerprintAsBitVect(mol, nBits=n_bits), \n",
    "    ##                     RDKFingerprint(mol, maxPath=5, fpSize=1024, nBitsPerHash=2)\n",
    "    ## Function to calculate molecular fingerprints given the number of bits and the method\n",
    "    return\n",
    "\n",
    "def print_fp(mol, method='maccs', n_bits=2048):\n",
    "    return(calculate_fp(mol, method='maccs', n_bits=2048).ToBitString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_calculate_fp.correction(print_fp) # rdkit molecule don't show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function helps us to create a data frame with the following additional columns:\n",
    "* Our molecules as molecule objects (created SMILES-strings)\n",
    "* The fingerprint as an python-object of the method of our choice (here MACCs)\n",
    "* The bit-vector of the fingerprint method of our choice as binary representation\n",
    "\n",
    "Therefore, we have two parameters: The data frame with a column named \"smiles\" with valid SMILES values, and the length of the fingerprint. The second argument is only used when others than MACCS fingerprint-method is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mol(df_l, n_bits):\n",
    "    # Construct a molecule from a SMILES string\n",
    "    # Generate mol column: Returns a Mol object, None on failure.\n",
    "    df_l['mol'] = df_l.smiles.apply(Chem.MolFromSmiles)\n",
    "    # Create a column for storing the molecular fingerprint as fingerprint object\n",
    "    df_l['bv'] = df_l.mol.apply(\n",
    "        # Apply the lambda function \"calculate_fp\" for each molecule\n",
    "        lambda x: calculate_fp(x, 'maccs', n_bits)\n",
    "    )\n",
    "    # Allocate np.array to hold fp bit-vector (np = numpy)\n",
    "    df_l['np_bv'] = np.zeros((len(df_l), df_l['bv'][0].GetNumBits())).tolist()\n",
    "    df_l.np_bv = df_l.np_bv.apply(np.array)\n",
    "    # Convert the object fingerprint to NumpyArray and store in np_bv\n",
    "    df_l.apply(lambda x: ConvertToNumpyArray(x.bv, x.np_bv), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Now let's start to load our data and to do the actual work. The *csv* file from **talktorial 2** is loaded into a dataframe with the important columns:\n",
    "\n",
    "* the CHEMBL-ID\n",
    "* the SMILES value of the corresponding compound\n",
    "* pIC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from previous talktorials\n",
    "df = pd.read_csv('../data/T2/EGFR_compounds_lipinski.csv', delimiter=';', index_col=0)\n",
    "# Look at head\n",
    "print(df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify data\n",
    "We need to classify each compound as active or inactive, therefore, we use the pIC50 value. \n",
    "* pIC50 = -log10(IC50) \n",
    "* IC50 describes the molar concentration (mol/L) that will result in 50 percent of inhibition in-vitro. \n",
    "* A common cut-off value to discretize pIC50 data is 6,3, which we will use for our experiment.\n",
    "* Note that there are several other suggestions for an activity cut-off ranging from an pIC50 value of 5 to 7 in the literature or even to define an exclusion range when not to take data points. \n",
    "\n",
    "Now we can use our functions defined above to generate our molecules and their fingerprints \n",
    "as well as specifying which molecule is active and which is not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df_new=df.drop(['units', 'IC50'], axis=1)\n",
    "# Create molecules from smiles and their fingerprints\n",
    "create_mol(df_new, 2048)\n",
    "# Add column for activity\n",
    "df_new['active'] = np.zeros(len(df_new))\n",
    "\n",
    "# Mark every molecule as active with an pIC50 of > 6.3\n",
    "df_new.loc[df_new[df_new.pIC50 >= 6.3].index, 'active'] = 1.0\n",
    "print('actives: %d, inactives: %d' % (df_new.active.sum(), len(df_new)-df_new.active.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning (ML)\n",
    "\n",
    "In the following we will try several ML approaches to classify our molecules. We will use:\n",
    "* Random Forest (RF)\n",
    "* Support Vector Machines (SVM) \n",
    "* Artificial Neural Networks (ANNs) \n",
    "\n",
    "Additionally, we will comment on the results. But before we start we define a function named `crossvalidation` which executes a cross validation procedure and returns measures such as accuracy, sensitivity and specificity.\n",
    "\n",
    "The goal is to test the ability of the model to predict data which it has never seen before in order to flag problems known as overfitting and to assess the generalization ability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for a cross-validation loop.\n",
    "def crossvalidation(model_l, df_l, n_folds=10):\n",
    "    # Given the selected model, the dataFrame and the number of folds the function executes a crossvalidation and returns\n",
    "    # accuracy, sensitivity, specificity for the prediction as well as fpr, tpr, roc_auc for each fold\n",
    "    \n",
    "    # Empty results vector\n",
    "    results = []\n",
    "    # Shuffle the indices for the k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    # Labels initialized with -1 for each data-point\n",
    "    labels = -1 * np.ones(len(df_l))\n",
    "    # Loop over the folds\n",
    "    for train_index, test_index in kf.split(df_l):\n",
    "        # Training\n",
    "        # Convert the bit-vector and the label to a list\n",
    "        train_x = df_l.iloc[train_index].bv.tolist()\n",
    "        train_y = df_l.iloc[train_index].active.tolist()\n",
    "        # Fit the model\n",
    "        model_l.fit(train_x, train_y)\n",
    "\n",
    "        # Testing\n",
    "        # Convert the bit-vector and the label to a list\n",
    "        test_x = df_l.iloc[test_index].bv.tolist()\n",
    "        test_y = df_l.iloc[test_index].active.tolist()\n",
    "        # Predict on test-set\n",
    "        prediction_prob = model_l.predict_proba(test_x)[:, 1]\n",
    "        # Save the predicted label of each fold\n",
    "        labels[test_index] = model_l.predict(test_x)\n",
    "\n",
    "        # Performance\n",
    "        # Get fpr, tpr and roc_auc for each fold\n",
    "        fpr_l, tpr_l, _ = roc_curve(test_y, prediction_prob)\n",
    "        roc_auc_l = auc(fpr_l, tpr_l)\n",
    "        # Append to results\n",
    "        results.append((fpr_l, tpr_l, roc_auc_l))\n",
    "\n",
    "    # Get overall accuracy, sensitivity, specificity\n",
    "    y = df_l.active.tolist()\n",
    "    acc = accuracy_score(df_l.active.tolist(), labels)\n",
    "    sens = recall_score(df_l.active.tolist(), labels)\n",
    "    spec = (acc * len(y) - sens * sum(y)) / (len(y) - sum(y))\n",
    "    return acc, sens, spec, results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we want to assess the quality of our models. Therefore we want to know the accuracy, sensitivity and specificity of our prediction. Additionally we focus on the so called ROC-curve. \n",
    "\n",
    "For reasons of clarity and comprehensibility of our code, we build a small function to plot our results. \n",
    "\n",
    "We will focus shortly on the following aspects:\n",
    "* Sensitivity\n",
    "* Specificity\n",
    "* Accuracy\n",
    "* ROC-curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0.1, 1.0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(acc, sens, spec, stat_res, main_text, file_name, plot_figure=1):\n",
    "    plt.figure(plot_figure, figsize=(7, 7))\n",
    "    cmap = cm.get_cmap('Blues')\n",
    "    \n",
    "    colors = [cmap(i) for i in np.linspace(0.3, 1.0, 10)]\n",
    "    #colors = [\"#3465A4\"]\n",
    "    for i, (fpr_l, tpr_l, roc_auc_l) in enumerate(stat_res):\n",
    "        plt.plot(fpr_l, tpr_l, label='AUC CV$_{0}$ = {1:0.2f}'.format(str(i),roc_auc_l), lw=2, color=colors[i])\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Random', lw=2, color=\"black\")  # Random curve\n",
    "    plt.xlabel('False positive rate', size=24)\n",
    "    plt.ylabel('True positive rate', size=24)\n",
    "    plt.title(main_text, size=24)\n",
    "    plt.tick_params(labelsize=16)\n",
    "    plt.legend(fontsize=16)\n",
    "    \n",
    "    # Save plot - use bbox_inches to include text boxes:\n",
    "    # https://stackoverflow.com/questions/44642082/text-or-legend-cut-from-matplotlib-figure-on-savefig?rq=1\n",
    "    plt.savefig(\"../data/T7/\" + file_name, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "    \n",
    "    plt.show()\n",
    "    # Calculate mean AUC and print\n",
    "    m_auc = np.mean([elem[2] for elem in r[3]])\n",
    "    print(f'Mean AUC: {m_auc}')\n",
    "\n",
    "    # Show overall accuracy, sensitivity, specificity\n",
    "    print(f'Sensitivity: {acc}\\nAccuracy: {sens}\\nSpecificity: {spec}\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier\n",
    "\n",
    "Now we will start with a random forest classifier. We will first set the parameters. Afterwards we will do the cross validation of our model and plot the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set model parameter for random Forest\n",
    "param = {'max_features': 'auto',\n",
    "         'n_estimators': 2000,\n",
    "         'criterion': 'entropy',\n",
    "         'min_samples_leaf': 1}\n",
    "modelRf = RandomForestClassifier(**param)\n",
    "\n",
    "# Do cross-validation procedure with 10 folds\n",
    "r = crossvalidation(modelRf, df_new, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the AUC results\n",
    "# r contains acc, sens, spec, and results\n",
    "print_results(r[0], r[1], r[2], r[3], 'Random forest ROC curves', 'rf_roc.png', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our models shows very good values for all measured values and, thus, seem to be predictive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector classifier\n",
    "Here we train a Support vector machine with a Radial-basis function kernel (also: squared-exponential kernel). \n",
    "For more information see [sklearn RBF kernel](http://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify model\n",
    "modelSvm = svm.SVC(kernel='rbf', C=1, gamma=0.1, probability=True)\n",
    "\n",
    "# Do cross-validation procedure with 10 folds\n",
    "r = crossvalidation(modelSvm, df_new, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "print_results(r[0], r[1], r[2], r[3],\n",
    "              'SVM$(rbf kernel)$ $C=1$ $\\gamma=0.1$ ROC curves', 'svm_roc.png', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network classifier\n",
    "The last approach we try here is a neural network model. We train an MLPClassifier (Multi-layer Perceptron classifier) with 3 layers, each with 5 neurons. You may notice early stopping is explicitely set to FALSE. As before, we do the crossvalidation procedure and plot the results. For more infor on MLP, see [sklearn MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify model, default activation: relu\n",
    "modelClf = MLPClassifier(solver='adam', \n",
    "                         alpha=1e-5, \n",
    "                         hidden_layer_sizes=(5, 3), \n",
    "                         random_state=1, early_stopping=False)\n",
    "\n",
    "# Do cross-validation procedure with 10 folds\n",
    "r = crossvalidation(modelClf, df_new, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "print_results(r[0], r[1], r[2], r[3], 'MLPClassifier ROC curves', 'mlp_roc.png', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbautoeval import run_yaml_quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_yaml_quiz(f\"../corrections/quiz/ML.yaml\", \"theoric-quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_yaml_quiz(f\"../corrections/quiz/ML.yaml\", \"code-quiz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teachopencadd",
   "language": "python",
   "name": "teachopencadd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
